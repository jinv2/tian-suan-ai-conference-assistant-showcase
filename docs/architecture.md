# 系统架构 (System Architecture)

本文档概述了天算AI会议助手系统的高层架构。该架构旨在实现可扩展性、可靠性和可维护性，利用了现代云原生原则和AI技术。

本文档概述了天算AI会议助手系统的高层架构。该架构旨在实现可扩展性、可靠性和可维护性，利用了现代云原生原则和AI技术。

![系统架构图](./architecture.png)
*(上图应可视化展示下述组件及其交互关系。)*

## 核心组件 (Core Components)

1.  **前端移动应用 (Mobile Application):**
    *   **平台：** 跨平台（React Native 或 Flutter），支持iOS和Android。
    *   **功能：** 为参会者提供用户界面，访问所有会议信息、与AI服务交互、管理个人资料、接收通知。
    *   **关键特性：** 个性化议程、AI聊天助手、室内外导航、AI签到（通过摄像头/二维码）、会中问答、通知推送、个人资料管理。

2.  **API 网关 (API Gateway):**
    *   **技术：** 标准API网关服务（如 AWS API Gateway, Kong, Nginx）。
    *   **功能：** 作为移动应用所有请求的单入口点。处理认证、授权、速率限制、请求路由和基本转换。将前端与后端微服务解耦。

3.  **后端微服务 (Backend Microservices):**
    *   **架构：** 一组独立的、专注的服务，通常通过REST API或消息队列通信。
    *   **技术：** Python (FastAPI/Django), Java (Spring Boot), 或 Go，使用Docker容器化。
    *   **服务示例：**
        *   **用户服务：** 管理用户资料、认证令牌、偏好设置。
        *   **会议服务：** 存储和提供会议元数据（议程、嘉宾、地点、文档）。
        *   **通知服务：** 处理向移动应用的推送通知。
        *   **签到服务：** 处理签到请求，需要时与CV模型交互。
        *   **互动服务：** 管理会中问答、投票、反馈。
        *   **导航服务：** 提供地图数据和路径规划信息。

4.  **AI 服务层 (AI Services Layer):**
    *   **功能：** 托管并提供系统所需的AI模型服务。以API形式暴露给后端微服务调用。
    *   **组件：**
        *   **LLM推理服务：** 托管微调后的大语言模型，用于问答、摘要等。包含RAG逻辑。
        *   **CV服务：** 托管计算机视觉模型（如人脸识别签到、异常检测）。
        *   **NLP服务：** 提供文本处理能力（语音转文本、情感分析）。
        *   **推荐服务：** 生成个性化推荐。

5.  **数据库与存储 (Databases & Storage):**
    *   **结构化数据：** 关系型数据库（如 PostgreSQL, MySQL）存储用户信息、会议日程、地点、注册详情、评分反馈。
    *   **非结构化/向量数据：** 向量数据库（如 Milvus, ChromaDB, FAISS）存储文档（报告、问答对）的嵌入向量，供RAG系统进行高效相似性搜索。
    *   **对象存储：** 云存储（如 AWS S3, Azure Blob Storage）存储大文件，如头像、演示文稿（PPT, PDF）、地图瓦片。
    *   **缓存：** 内存数据存储（如 Redis, Memcached）缓存常用数据（如当前议程、热门问题）以提升性能。

6.  **云平台 (Cloud Platform):**
    *   整个后端系统（微服务、AI模型、数据库）部署在主流云平台（如 AWS, Azure, 阿里云）上，以获得可扩展性、可靠性和托管服务。可能使用Kubernetes进行容器编排。

## 数据流示例 - AI 问答 (Data Flow Example - AI Q&A)

1.  参会者在移动应用的AI助手中提问。
2.  应用通过HTTPS将查询发送到API网关。
3.  网关认证请求并将其路由到相关的后端微服务（例如，互动服务）。
4.  互动服务记录查询并调用AI服务层（LLM推理服务）。
5.  LLM服务执行RAG（检索增强生成）：
    *   根据查询的嵌入向量，在向量数据库中查询相关的文档片段。
    *   也可能通过其他服务查询SQL数据库以获取结构化上下文（例如，用户的当前位置、即将开始的议程）。
    *   构建一个包含原始查询和检索到的上下文的提示（Prompt）。
    *   将提示发送给微调后的LLM进行生成。
6.  LLM *仅* 基于提供的上下文及其微调后的知识生成答案。
7.  答案通过各服务层返回到移动应用。
8.  应用向参会者显示答案。

这种模块化架构允许系统不同部分的独立扩展和开发，并便于集成各种AI能力。
